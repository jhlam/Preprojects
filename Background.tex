\chapter{Background} \lable{chap_background}

In this chapter, we will look at the fundamental concepts and background information needed to understand the the different infections model, problem with seed-selection for social networks, and solving Breadth-first search using matrix multiplication. This chapter will contain notations that we would use throughout the report and used in the field. 

\section{Glossary of terms}
\begin{center}
    \begin{tabular}{| l |}
    	\hline
    	\it{Vertex} (pl. vertices): The fundamental unit of a network, also called a site(physics), a node (computer science), or an actor (sociology).
		\it{Edge}: The line connecting two vertices. Also called a bond (physics), a link(computer science), or a tie (sociology).
		\it{Directed/undirected}: An edge is directed if it runs in only one direction (such as a one-way road between two points), and undirected if it runs in both directions. Directed edges, which are sometimes called arcs, can be thought of as sporting arrows indicating their orientation. A graph is directed if all of its edges are directed. An undirected graph can be represented by a directed one having two edges between each pair of connected vertices, one in each direction.
		\it{Degree}: The number of edges connected to a vertex. Note that the degree is not necessarily equal to the number of vertices adjacent to a vertex, since there may be more than one edge between any two vertices. In a few recent articles, the degree is referred to as the “connectivity” of a vertex, but we avoid this usage because the word connectivity already has another meaning in graph theory. A directed graph has both an in-degree and an out-degree for each vertex, which are the numbers of in-coming and out-going edges respectively.
		\it{Component}: The component to which a vertex belongs is that set of vertices that can be reached from it by paths running along edges of the graph. In a directed graph a vertex has both an in-component and an out-component, which are the sets of vertices from which the vertex can be reached and which can be reached from it.
		\it{Geodesic path}: A geodesic path is the shortest path through the network from one vertex to another. Note that there may be and often is more than one geodesic path between two vertices.
		\it{Diameter}: The diameter of a network is the length (in number of edges) of the longest geodesic path between any two vertices. A few authors have also used this term to mean the average geodesic distance in a graph, although strictly the two quantities are quite distinct.
    
    \hline
    \end{tabular}
\end{center}


\section{Network}
A {\it network} is a collection of {\it Vertices}, commonly known as nodes with \{it edges} connecting them together\cite{ComplexNetwork2003}. The edges serves as a connection, or a \"bridge\" between the nodes, while the nodes can reprecent something, or containing information. In the real world, multiple systems takes the form of networks around the world, examples are the internettt, the World Wide Web, social media like Facebook, twitter etc.  There are different types of network or " {\it graphs}. These include from {\it social network}, {\it sinformation networks}, {\it technological networks} ,and {\it biological network}.  Each of them have a different properties, but we will focus more about social network.

A social network is a set of people connected to each other via some form of contact or interactions\cite{ComplexNetwork2003}. The nodes are people while the edges are the connections between peoples. The social network display information regarding connection, interaction or location of a set of people.It forms patterns regarding friendships, business interactions between companies and families history/ ancestral tree. The social network is often used in social science\cite{ComplexNetwork2003}. Some noteable experiments are \cite{smallWorldExperiment}, which looks at the small world problem. The small world problem can be summarized as: \"what is the probability that any two people, selected arbitrarily from a large population, such as that of the United States, will know each other?\"\cite{SmallworldExperiment1969}. This in itselfe is not that interesting, the \cite{SmallworldExperiment1969} takes that altho person {\it a} and {\it z} does not know each other, do they have a set of individuals \{{\it b_1, b_2, ... b_n}\} who are mutual friend or even a \"chain\" of such individual({\it a-b-c-...-y.z}).

Some properties that networks often exhibits are the small world effect, transitivity or clustering, degree correlations, and community structure\cite{ComplexNetwork2003}.

\subsection{The small world effect}
The small world effect was first demonstrated by Stanley Milgra in the 1960s during his famous letter passing experiment\cite{SmallWorldProblemSmilgram1960}. The experiment was about passing letters from person to person to reach a designated target with only small steps. For the published case, the chain was around six \cite{Experiment1969}. This shows us that for most pair of vertices can reach each other with a short parth. A more precise wording is that \"Networks are said to show the small world effect if the value of \it{l} scales logarithmically or slower with the network size for a fixed mean degree.\"\cite{ComplexNetwork2003}We have defined \it{l} to be the mean geodesic distance between vertex pairs in a network. 

\subsection{Transistivity/clustering}
Transistivity, also sometimes called clustering is the properties that shows that there is a high number of triangles in the network. A triangle in a network is if node A is connected to node B and node C, and node B and C is also connected to each other, thus creating a triangle. In social network, we say that a friend of your friend is likely to be your friend too\cite{ComplexNetwork2003}. The transistivity is often used to show \it{network density}

\subsection{Network resilience}
For most network model, there is the need to remove nodes from the network. Removal of a node can have no effect on the network as a whole, or it can be devastating. Network resilience looks at how the network can ressist to such a removal. There are two different removal scheme, the random removal where nodes are randomly picked and removed, or the targeted removal where specific nodes are removed depending on the critteria. 

The experiment mentioned in \cite{complexNetwork} by Albert \it{et al} showed that for a subset of network representing the internett and the world wide web, targeted removal had a larger impact then random removal. The targeted removal removed the highest degree nodes from the network, and the random removal removed nodes randomly. The random removal had a minimal effect on the network, while the targeted removal had a much larger impact, the mean vertex-vertex distance increased. They proposed that the internett was highly resilient to random removal, while much more vuarneble to targeted removal. 

There are other studies that proposed a different interpetation about the data found.	

\subsection{Degree correlation}



\subsection{community structure}



\section{Data diffusion}
Data diffusion is looking at how information is propagated through a network or a graph. An example would be how a new Internet meme, a new trend or how a new disease is spread through a community. The process consist of a set of starter nodes that are \"infected\", during each time-step, there are a chance that the \"infected\" node would \"infect\" its neighbor. To start such a simulation, we would need to first pick out a set of initial \"starter node\". These {\it k} starter node is a set of node that in the initial time-step is infected. They will pass on the information/infection during each time-step and the information/infection will propagate through the network.

\section{Basic Diffusion Models}
When we talk about information propagation, we can look at how medical and technological innovations is spread through a social network. We can simulate those kind of behavior with different diffusion models. There are two basic diffusion models used to simulate the propagation of information through a network\cite{MaximizeSpread2003}, the {\it linear threshold model} and the {\it independent cascade model}\cite{MaximizeSpread2003}.

This process can be simulated by looking at a social network and how information propagates through the network. We look at each node in the graph as a person, they can be either active, or inactive. The activation of a node depends on which diffusion model we choose. A active node is \"infected\", while the inactive is the \"healthy\" ones. The activation of each nodes is dependent on which model we pick.

The linear threshold model uses a threshold $\theta_v$ between the interval [0,1], which represent the faction of {\it v}'s neighbors that need to be active to activate node{\it v}. The Linear Threshold Model activates the current node {\it v} when the weight{\it b_{v,w}} $> \theta$ from its neighbor {\it w} outweighs the $\theta_v$. This is more in line with the situation were each person have a chance to adopt to a new trend if exposed to the trend enough time by his close friends. An example would be a product promoted on social network like twitter and Facebook. The user will adopt the new trend if he is exposed to it from enough friends or idols. 

The independent cascade model changes states with a probability $p_{\it v, w}$, where {\it v }is current node, and {\it w} is it's neighbor. During each propagation, the node {\it v} have a  $p_{\it v, w}$ chance to change state if the neighbor {\it w} changed state. If during time-step {\it t} a node {\it v} changed state, its neighbor {\it w} would have a  $p_{\it v, w}$ chance to change state in the next time step. An example here would be spread of a disease. The current node {\it v} have a chance($\theta_v$) to infect its neighbor

\section{Breadth First Search as a matrix multiplication.}
By looking at the 	connectivity matrix, we can see that a connectivity matrix is a graph represented in a matrix format. The BFS can be achieved by looking at the BFS operations as a matrix multiplication \cite{algoToMath}. If we look at the graph as a connectivity matrix, we can apply matrix multiplication to generate the breadth first search. 

\section{SIR/SIS}
There are two different epidemic model that we will be looking at, the {\it SIR} ( susceptible, infected, removed,) and the SIS mode(susceptible, infected, susceptible).Both is used to simulate how a disease or an epidemic can spread through the general population, in this case, we can use this 

The SIR model stands for susceptible, infected and removed. The node would have three different states, the susceptible state mean that the node is susceptible to the disease, or in this example, change state. The infected state is the state were the node {\it v} is infected. The state Removed/Recovered, is the state were the node {\it v} have the disease removed, or have recover from the infection. In this model, the Removed/Recovered state is not susceptible to the infection again. 

The SIS stands for susceptible, infected and susceptible. Unlike the SIR this model can reinfect the recovered nodes. This model is used for simulation of outbreak of disease. 

\section{greedy algorithm}
The greedy algorithm was proposed by [KEMPE]. The algorithm is a greedy hillclimbing algorithm, the algorithm fins the starter set of nodes \it{S} by iterating through all the vertex in \it{V} and calculate the total amount of spread. The spread is saved and the \it{k} most influential nodes would be choosen. @@@INSERT PSAUDOCODE HERE@@@@@@ 



\section{R-mat}
One problem during graph analysation is finding suiteble graphs to analyse. to generate graphs with desirede properties is not easdy to do. One solution proposed på \cite{RMat2004} is to use the /"recursive matrix /" or R-mat model. The R-mat model generates graph with only a few parameters, the graph will naturally have the small world propertie and follows the laws of normal graphs, and have a quick generation speed. The R-mat models goal is to generate graphs that matches the degree distribution, exhibits a \" community \" structure and have a small diameter and mathces other criteria.\cite{Rmat2004}.

The algorithm to generate such a recursive matrix is as follow: The idea is to partition the adjacency matrix into four equally sized part branded A,B,C,D. Each new edge is \"Droped\" onto the adjacency matrix. Wich section the edge would be placed on is choosen randomly. Each section have a `probability of \it{a, b, c, d}, and $a + b + c + d = 1$. After a section is choosen, the partion that was choosen is partitioned again. This continoues until the choosen section is a 1x1 square and the edge is dropped there. 

@@
INSET PICTURE OF PARTITION HERE!

From the algorithm, we can see that the R-mat generator is capable to generate graphs with total numbers of node \it{V} = \power{2,x}. Since the algorithm partitioned the matrix into four part. 

\section{Cache oblivious model}
The cache oblivious model 
